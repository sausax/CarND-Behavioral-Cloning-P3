{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "def read_imgs(img_paths):\n",
    "    imgs = np.empty([len(img_paths), 160, 320, 3])\n",
    "\n",
    "    for i, path in enumerate(img_paths):\n",
    "        imgs[i] = imread(path)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "def resize(imgs, shape=(32, 16, 3)):\n",
    "    \"\"\"\n",
    "    Resize images to shape.\n",
    "    \"\"\"\n",
    "    height, width, channels = shape\n",
    "    imgs_resized = np.empty([len(imgs), height, width, channels])\n",
    "    for i, img in enumerate(imgs):\n",
    "        imgs_resized[i] = imresize(img, shape)\n",
    "\n",
    "    return imgs_resized\n",
    "\n",
    "def rgb2gray(imgs):\n",
    "    \"\"\"\n",
    "    Convert images to grayscale.\n",
    "    \"\"\"\n",
    "    return np.mean(imgs, axis=3, keepdims=True)\n",
    "\n",
    "def normalize(imgs):\n",
    "    \"\"\"\n",
    "    Normalize images between [-1, 1].\n",
    "    \"\"\"\n",
    "    return imgs / (255.0 / 2) - 1\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_processed = resize(imgs)\n",
    "    imgs_processed = rgb2gray(imgs_processed)\n",
    "    imgs_processed = normalize(imgs_processed)\n",
    "\n",
    "    return imgs_processed\n",
    "\n",
    "def random_flip(imgs, angles):\n",
    "    \"\"\"\n",
    "    Augment the data by randomly flipping some angles / images horizontally.\n",
    "    \"\"\"\n",
    "    new_imgs = np.empty_like(imgs)\n",
    "    new_angles = np.empty_like(angles)\n",
    "    for i, (img, angle) in enumerate(zip(imgs, angles)):\n",
    "        if np.random.choice(2):\n",
    "            new_imgs[i] = np.fliplr(img)\n",
    "            new_angles[i] = angle * -1\n",
    "        else:\n",
    "            new_imgs[i] = img\n",
    "            new_angles[i] = angle\n",
    "\n",
    "    return new_imgs, new_angles\n",
    "\n",
    "def augment(imgs, angles):\n",
    "    imgs_augmented, angles_augmented = random_flip(imgs, angles)\n",
    "\n",
    "    return imgs_augmented, angles_augmented\n",
    "\n",
    "def gen_batches(imgs, angles, batch_size):\n",
    "    \"\"\"\n",
    "    Generates random batches of the input data.\n",
    "    :param imgs: The input images.\n",
    "    :param angles: The steering angles associated with each image.\n",
    "    :param batch_size: The size of each minibatch.\n",
    "    :yield: A tuple (images, angles), where both images and angles have batch_size elements.\n",
    "    \"\"\"\n",
    "    num_elts = len(imgs)\n",
    "\n",
    "    while True:\n",
    "        indeces = np.random.choice(num_elts, batch_size)\n",
    "        batch_imgs_raw, angles_raw = read_imgs(imgs[indeces]), angles[indeces].astype(float)\n",
    "\n",
    "        batch_imgs, batch_angles = augment(preprocess(batch_imgs_raw), angles_raw)\n",
    "\n",
    "        yield batch_imgs, batch_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project.\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, ELU, Flatten\n",
    "from keras.layers import Conv2D, ConvLSTM2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of the simulator data.\n",
    "DATA_FILE = '/Users/saurabh/Downloads/car_output/driving_log.csv'\n",
    "\n",
    "# Load the training data from the simulator.\n",
    "cols = ['center_image', 'left_image', 'right_image', 'steering_angle', 'throttle', 'break', 'speed']\n",
    "data = pd.read_csv(DATA_FILE, names=cols, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saurabh/Downloads/car_output/IMG/center_2017_04_27_11_00_10_729.jpg\n"
     ]
    }
   ],
   "source": [
    "print data['center_image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3f9e20025201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-3f9e20025201>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msplit_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('imgs_dir', '/Users/saurabh/Downloads/car_output/IMG/', 'The directory of the image data.')\n",
    "#flags.DEFINE_string('data_path', DATA_FILE, 'The path to the csv of training data.')\n",
    "#flags.DEFINE_integer('batch_size', 128, 'The minibatch size.')\n",
    "#flags.DEFINE_integer('num_epochs', 10, 'The number of epochs to train for.')\n",
    "#flags.DEFINE_float('lrate', 0.0001, 'The learning rate for training.')\n",
    "batch_size =128\n",
    "num_epochs = 10\n",
    "lrate = 0.0001\n",
    "\n",
    "def main():\n",
    "    ##\n",
    "    # Load Data\n",
    "    ##\n",
    "\n",
    "    with open(DATA_FILE, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # data is a list of tuples (img path, steering angle)\n",
    "        data = np.array([row for row in reader])\n",
    "\n",
    "    # Split train and validation data\n",
    "    np.random.shuffle(data)\n",
    "    split_i = int(len(data) * 0.9)\n",
    "    X_train, y_train = list(zip(*data[:split_i]))\n",
    "    X_val, y_val = list(zip(*data[split_i:]))\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "    ##\n",
    "    # Define Model\n",
    "    ##\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, 3, 3, input_shape=(32, 16, 1), border_mode='same', activation='relu'),\n",
    "        Conv2D(64, 3, 3, border_mode='same', activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Conv2D(128, 3, 3, border_mode='same', activation='relu'),\n",
    "        Conv2D(256, 3, 3, border_mode='same', activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, name='output', activation='tanh'),\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(lr=lrate), loss='mse')\n",
    "\n",
    "    ##\n",
    "    # Train\n",
    "    ##\n",
    "\n",
    "    history = model.fit_generator(gen_batches(X_train, y_train, batch_size),\n",
    "                                  len(X_train),\n",
    "                                  num_epochs,\n",
    "                                  validation_data=gen_batches(X_val, y_val, batch_size),\n",
    "                                  nb_val_samples=len(X_val))\n",
    "\n",
    "    ##\n",
    "    # Save model\n",
    "    ##\n",
    "\n",
    "    json = model.to_json()\n",
    "    model.save_weights('save/model.h5')\n",
    "    with open('save/model.json', 'w') as f:\n",
    "        f.write(json)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
